# -*- coding: utf-8 -*-
"""plnUSP_lista2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sZoggL9zCRs1kFj9txEm_b0iHSMsoTDi

***Curso de Extensão em Processamento de Linguagem Natural com Python***
---
*Instituto de Ciências Matemáticas e de Computação da Universidade de São Paulo (ICMC-USP)*


---
Leandro de Assis Madeira - 2021

Instalando a biblioteca NLTK (Natural Language Toolkit)
"""

pip install nltk

import nltk
nltk.download()

"""# ***Lista de Exercícios 2***

---
*22 de setembro de 2021*

1. Crie uma variável com a string “ instituto de ciências matemáticas e de
computação” e faça:
"""

'''a. Concatene (adicione) uma outra string chamada “usp”'''

z = ' instituto de ciências matemáticas e de computação '
z = z + 'usp'
print(z)

'''b. Concatene (adicione) uma outra informação: 2021'''

z = z + ' 2021'
print(z)

''' c. Verifique o tamanho da nova string (com as informações adicionadas
    das questões a e b), com referência a caracteres e espaços'''

len(z)

'''d. Transforme a string inteiramente em maiúsculo'''

z.upper()

'''e. Transforme a string inteiramente em minúsculo'''

z.lower()

'''f. Retire o espaço que está no início da string e imprima a string'''

z.strip()

'''g. Substitua todas as letras ‘a’ por ‘x’'''

z.replace('a', 'x')

'''h. Separe a string em palavras únicas'''

z.split()

'''i. Verifique quantas palavras existem na string'''

len(z.split())

'''j. Separe a string por meio da palavra “de”'''

z1 = z.split('de')
z1

''' k. Verifique agora quantas palavras/frases foram formadas quando houve
    a separação pela palavra “de”'''

len(z1)

''' l. Junte as palavras que foram separadas (pode usar a separação resultante
    da questão h ou j)'''

z2 = "de".join(z1)
z2

''' m. Junte as palavras que foram separadas, mas agora separadas por uma
    barra invertida, não por espaços (pode usar a separação resultante da
    questão h ou j)'''

z3 = "\\".join(z1)
z3

"""2. Escolha um corpus qualquer (pode ser o que foram utilizados na aula) e,
usando as funções do NLTK, faça:
"""

'''a. Tokenize o corpus inteiro (palavras, números e pontuações)'''

corpus = open('/content/corpus_teste.txt').read()
print(corpus)

nltk.word_tokenize(corpus)

'''b. Verifique a quantidade de tokens do corpus'''

quantidade = nltk.FreqDist(corpus)
quantidade

'''c. Tokenize o corpus apenas por suas palavras'''

from nltk.tokenize import RegexpTokenizer
tokenizer = RegexpTokenizer(r' [A-z]\w*')
tokens = tokenizer.tokenize(corpus)
tokens

'''d. Verifique a quantidade de palavras do corpus'''

palavras = nltk.FreqDist(tokens)
palavras

'''e. Verifique a frequência de palavras no corpus'''

plv = nltk.FreqDist(palavras)
plv

'''f. Verifique quais são as 5, 10 e 15 palavras mais frequentes do corpus'''

top5 = palavras.most_common(5)
top10 = palavras.most_common(10)
top15 = palavras.most_common(15)
print(top5)
print(top10)
print(top15)

'''g. Extraia as stopwords do NLTK (não do corpus ainda)'''
nltk.corpus.stopwords.words('portuguese')

'''h. Verifique a frequência dos tokens sem stopwords do corpus'''

stopwords = nltk.corpus.stopwords.words('portuguese')
tokens_sem_stopwords = [w.lower() for w in tokens if w not in stopwords]
frqnc = nltk.FreqDist(tokens_sem_stopwords)
print(frqnc.most_common())

